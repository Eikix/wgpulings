# Exercise definitions for wgpulings
# Each exercise has:
# - name: The exercise file name
# - path: Path to the exercise file
# - mode: "compile" or "run" (compile checks it builds, run checks output)
# - hint: Help text shown when the user asks for a hint

# INTRO - Understanding GPU Fundamentals
[[exercises]]
name = "intro1"
path = "exercises/intro/intro1.rs"
mode = "compile"
hint = """
GPU programming is fundamentally different from CPU programming. The GPU excels at
doing the same operation on many pieces of data in parallel (SIMD - Single Instruction,
Multiple Data).

Key concepts:
- The GPU has its own memory (VRAM)
- Data needs to be uploaded from CPU to GPU
- The GPU executes programs called "shaders"
- There are different types of shaders: vertex, fragment, compute

Read through the code and fix the I AM NOT DONE markers to proceed."""

[[exercises]]
name = "intro2"
path = "exercises/intro/intro2.rs"
mode = "compile"
hint = """
wgpu follows the WebGPU standard, which provides a modern, safe API for GPU programming.

The basic setup involves:
1. Instance - The entry point to wgpu
2. Adapter - Represents a physical GPU
3. Device - A logical connection to the GPU
4. Queue - Used to submit commands to the GPU

The RequestAdapterOptions let you specify which GPU to use (high performance, low power, etc.)."""

[[exercises]]
name = "intro3"
path = "exercises/intro/intro3.rs"
mode = "compile"
hint = """
A render pass is how you tell the GPU "I want to draw something now".

Key components:
- RenderPassDescriptor defines what you want to do
- ColorAttachment specifies which texture to draw to
- load_op: What to do at the start (clear, load existing)
- store_op: What to do at the end (store, discard)

Think of it like opening a canvas, painting on it, then deciding whether to save it."""

# BASICS - First Renders
[[exercises]]
name = "basics01"
path = "exercises/basics/basics01.rs"
mode = "run"
hint = """
Clearing the screen is the simplest GPU operation. You're telling the GPU:
"Fill this entire texture with one color."

The color is specified as RGBA values from 0.0 to 1.0:
- r: 1.0 = full red
- g: 1.0 = full green
- b: 1.0 = full blue
- a: 1.0 = fully opaque

Try changing the clear color to see the effect!"""

[[exercises]]
name = "basics02"
path = "exercises/basics/basics02.rs"
mode = "run"
hint = """
Drawing a triangle is the "Hello World" of GPU programming!

Every piece of geometry on the GPU is made of triangles. To draw one, you need:
1. Vertex data (positions of the three corners)
2. A vertex shader (processes each vertex)
3. A fragment shader (colors each pixel)

The vertex shader runs once per vertex (3 times for a triangle).
The fragment shader runs once per pixel inside the triangle (could be thousands of times!).

Look for the vertex positions and make sure they're in clip space (-1.0 to 1.0)."""

[[exercises]]
name = "basics03"
path = "exercises/basics/basics03.rs"
mode = "run"
hint = """
Vertex colors allow each corner of the triangle to have a different color.
The GPU automatically interpolates (blends) the colors between vertices!

This is called "varying" data - it varies across the surface of the triangle.

Your Vertex struct needs to include color data, and you need to:
1. Add color to the vertex buffer layout
2. Pass color from vertex shader to fragment shader
3. Use the interpolated color in the fragment shader"""

[[exercises]]
name = "basics04"
path = "exercises/basics/basics04.rs"
mode = "run"
hint = """
Buffers are how you send data from CPU to GPU.

Key types:
- Vertex buffer: Holds vertex data (positions, colors, etc.)
- Index buffer: Defines which vertices form triangles
- Uniform buffer: Holds constants like transforms, time, etc.

To create a buffer:
1. Create it with wgpu::Device::create_buffer_init()
2. Specify the usage (VERTEX, INDEX, UNIFORM, etc.)
3. The contents must be &[u8], use bytemuck::cast_slice()

Remember: The GPU can't access CPU memory directly!"""

# SHADERS - WGSL Fundamentals
[[exercises]]
name = "shaders01"
path = "exercises/shaders/shaders01.wgsl"
mode = "compile"
hint = """
WGSL (WebGPU Shading Language) is the shader language for WebGPU.

Basic syntax:
- Variables: var name: type = value;
- Constants: const name: type = value;
- Functions: fn name(params) -> return_type { }
- Built-in types: f32, i32, u32, vec2<f32>, vec3<f32>, vec4<f32>, mat4x4<f32>

Comments use // for single line

Shader entry points need the @vertex or @fragment attribute."""

[[exercises]]
name = "shaders02"
path = "exercises/shaders/shaders02.wgsl"
mode = "compile"
hint = """
The vertex shader's job is to transform vertex positions from model space
to clip space (normalized device coordinates from -1 to 1).

Input: Vertex attributes (position, color, UV, etc.)
Output: Built-in position (@builtin(position)) and any varying data

The @location(N) attribute specifies which input/output slot to use.
These numbers must match between:
- Rust vertex buffer layout -> Vertex shader input
- Vertex shader output -> Fragment shader input"""

[[exercises]]
name = "shaders03"
path = "exercises/shaders/shaders03.wgsl"
mode = "compile"
hint = """
The fragment shader determines the final color of each pixel.

Input: Interpolated varying values from the vertex shader
Output: Color value(s) to write to render target(s)

The @location(0) on the return value specifies which color attachment to write to.

vec4<f32> is used for colors: (red, green, blue, alpha) all from 0.0 to 1.0"""

[[exercises]]
name = "shaders04"
path = "exercises/shaders/shaders04.wgsl"
mode = "compile"
hint = """
Uniform buffers hold data that's constant for an entire draw call.
Common uses: transformation matrices, time, light positions, material properties.

To use uniforms in WGSL:
1. Declare a struct for the data
2. Declare the uniform: @group(0) @binding(0) var<uniform> name: Type;
3. Use it in your shader code

The @group and @binding numbers must match the bind group layout in Rust.
"""

[[exercises]]
name = "shaders05"
path = "exercises/shaders/shaders05.wgsl"
mode = "compile"
hint = """
"Varying" is the term for data passed from vertex to fragment shader.
It's called varying because it's interpolated across the triangle.

Vertex shader output -> GPU interpolates -> Fragment shader input

Example: If one vertex is red and another is blue, pixels in between
will be automatically blended from red to purple to blue!

The @location numbers must match between vertex output and fragment input."""

# 2D GRAPHICS
[[exercises]]
name = "graphics2d01"
path = "exercises/graphics2d/graphics2d01.rs"
mode = "run"
hint = """
Index buffers let you reuse vertices. A rectangle has 4 corners but 6 vertices
if you draw it as 2 triangles without indices.

With indices:
- 4 vertices defining the corners
- 6 indices: [0,1,2, 0,2,3] defining two triangles

This saves memory and processing time!

Use BufferUsages::INDEX and render_pass.set_index_buffer()."""

[[exercises]]
name = "graphics2d02"
path = "exercises/graphics2d/graphics2d02.rs"
mode = "run"
hint = """
Textures are images loaded into GPU memory.

Steps:
1. Load image with image::load_from_memory() or similar
2. Create a texture with device.create_texture()
3. Upload data with queue.write_texture()
4. Create a texture view and sampler
5. Bind them in a bind group

The texture format (Rgba8UnormSrgb) determines how colors are stored."""

[[exercises]]
name = "graphics2d03"
path = "exercises/graphics2d/graphics2d03.wgsl"
mode = "compile"
hint = """
To sample a texture in WGSL:

@group(0) @binding(0) var my_texture: texture_2d<f32>;
@group(0) @binding(1) var my_sampler: sampler;

// In fragment shader:
let color = textureSample(my_texture, my_sampler, uv_coords);

UV coordinates range from (0,0) at top-left to (1,1) at bottom-right.
The sampler controls filtering (nearest, linear) and wrapping (repeat, clamp)."""

[[exercises]]
name = "graphics2d04"
path = "exercises/graphics2d/graphics2d04.rs"
mode = "run"
hint = """
Alpha blending allows transparency. The blend function combines the new color
with the color already in the framebuffer.

Common blend modes:
- Alpha blend: new_color * alpha + old_color * (1 - alpha)
- Additive: new_color + old_color (for lights, particles)
- Multiply: new_color * old_color (for shadows, tinting)

Set blend state in the ColorTargetState when creating the render pipeline."""

# 3D GRAPHICS
[[exercises]]
name = "graphics3d01"
path = "exercises/graphics3d/graphics3d01.rs"
mode = "run"
hint = """
3D coordinate systems typically use:
- X axis: right
- Y axis: up
- Z axis: forward (or backward depending on convention)

wgpu uses a right-handed coordinate system with:
- X+ right, Y+ up, Z+ toward you (out of screen)

Positions are initially in "model space" (relative to the object).
Transformations convert through: model -> world -> view -> clip space."""

[[exercises]]
name = "graphics3d02"
path = "exercises/graphics3d/graphics3d02.rs"
mode = "run"
hint = """
Transformations move, rotate, and scale objects.

- Translation: Move (x, y, z)
- Rotation: Around an axis by an angle
- Scale: Multiply size by (sx, sy, sz)

These are represented as 4x4 matrices. Order matters!
Typically: Scale -> Rotate -> Translate

Use cgmath or glam crates for matrix math."""

[[exercises]]
name = "graphics3d03"
path = "exercises/graphics3d/graphics3d03.rs"
mode = "run"
hint = """
Matrices are the fundamental tool for 3D transformations.

Key matrix types:
- Model matrix: Object's position/rotation/scale in world
- View matrix: Camera's position and orientation (inverse of camera transform)
- Projection matrix: 3D to 2D projection (perspective or orthographic)

Combined: MVP = Projection * View * Model

Multiply in vertex shader: clip_pos = mvp * vec4<f32>(vertex_pos, 1.0);"""

[[exercises]]
name = "graphics3d04"
path = "exercises/graphics3d/graphics3d04.rs"
mode = "run"
hint = """
A camera defines what part of the 3D world is visible.

Components:
- Position: Where the camera is (eye)
- Target: What it's looking at
- Up vector: Which way is up (usually (0, 1, 0))

The view matrix converts from world space to camera space.
Use cgmath::Matrix4::look_at_rh() or similar."""

[[exercises]]
name = "graphics3d05"
path = "exercises/graphics3d/graphics3d05.rs"
mode = "run"
hint = """
Perspective projection makes distant objects appear smaller (like real life).

Parameters:
- FOV (field of view): How wide the view is (typically 45-90 degrees)
- Aspect ratio: Width / height
- Near plane: Closest visible distance
- Far plane: Farthest visible distance

Use cgmath::perspective() to create the projection matrix.

Alternative: Orthographic projection (no perspective, used for 2D or technical views)."""

[[exercises]]
name = "graphics3d06"
path = "exercises/graphics3d/graphics3d06.rs"
mode = "run"
hint = """
The depth buffer (Z-buffer) determines which objects are in front of others.

For each pixel:
1. Fragment shader runs
2. Depth value is compared with depth buffer
3. If closer (depth test passes), update color and depth
4. If farther, discard the fragment

Enable with:
- depth_stencil attachment in render pass
- depth_stencil state in pipeline (comparison function, write enabled)

Format: Depth32Float or Depth24Plus"""

# LIGHTING
[[exercises]]
name = "lighting01"
path = "exercises/lighting/lighting01.wgsl"
mode = "compile"
hint = """
Surface normals are vectors perpendicular to a surface.
They're essential for lighting calculations.

Key points:
- Normals should be unit vectors (length 1)
- Normals in vertex data need to be transformed to world space
- Normal transformation uses the inverse transpose of the model matrix
- For lighting, you often need to normalize after interpolation

vec3<f32> normal = normalize(interpolated_normal);"""

[[exercises]]
name = "lighting02"
path = "exercises/lighting/lighting02.wgsl"
mode = "compile"
hint = """
Diffuse lighting (Lambertian) makes surfaces brighter when facing the light.

Formula: diffuse = max(dot(normal, light_dir), 0.0) * light_color

- normal: Surface normal (unit vector)
- light_dir: Direction TO the light (unit vector)
- dot product gives cosine of angle between them
- max() prevents negative values (surfaces facing away are dark)

This simulates rough surfaces that scatter light equally in all directions."""

[[exercises]]
name = "lighting03"
path = "exercises/lighting/lighting03.wgsl"
mode = "compile"
hint = """
Specular lighting creates shiny highlights based on view angle.

Formula: specular = pow(max(dot(view_dir, reflect_dir), 0.0), shininess)

- view_dir: Direction TO the viewer
- reflect_dir: Light direction reflected across normal
- shininess: Higher = smaller, sharper highlight
- Use reflect() built-in to calculate reflection

This simulates smooth surfaces that reflect light like mirrors."""

[[exercises]]
name = "lighting04"
path = "exercises/lighting/lighting04.wgsl"
mode = "compile"
hint = """
The Phong lighting model combines:
1. Ambient: Base lighting (simulates indirect light)
2. Diffuse: Direction-dependent brightness
3. Specular: Shiny highlights

final_color = ambient + diffuse + specular;

Each component can have its own color/intensity.
Material properties control how much of each to apply."""

[[exercises]]
name = "lighting05"
path = "exercises/lighting/lighting05.wgsl"
mode = "compile"
hint = """
Multiple lights are applied by summing their contributions.

struct Light {
    position: vec3<f32>,
    color: vec3<f32>,
    intensity: f32,
}

For each light:
1. Calculate light_dir and distance
2. Calculate diffuse and specular
3. Apply attenuation (light weakens with distance)
4. Sum all light contributions

Attenuation: 1.0 / (1.0 + distance * distance)"""

# ADVANCED
[[exercises]]
name = "advanced01"
path = "exercises/advanced/advanced01.rs"
mode = "run"
hint = """
Compute shaders are general-purpose GPU programs.
Unlike vertex/fragment shaders, they don't render - they process data.

Use cases:
- Particle simulations
- Image processing
- Physics calculations
- AI/ML inference

Entry point: @compute @workgroup_size(X, Y, Z)
The GPU runs many workgroups in parallel, each with multiple threads."""

[[exercises]]
name = "advanced02"
path = "exercises/advanced/advanced02.wgsl"
mode = "compile"
hint = """
Storage buffers are read-write buffers accessible in compute shaders.

@group(0) @binding(0) var<storage, read_write> data: array<f32>;

Access with: data[index] = value;

Unlike uniform buffers (read-only, small), storage buffers can be:
- Very large (many MB or GB)
- Written to from shaders
- Used for arbitrary data structures

Common pattern: Read input buffer, process, write output buffer."""

[[exercises]]
name = "advanced03"
path = "exercises/advanced/advanced03.rs"
mode = "run"
hint = """
Instancing draws the same object many times with different transforms.
This is much faster than separate draw calls!

Instead of:
for obj in objects { set_uniform(transform); draw(); }

Use:
set_instance_buffer(all_transforms); draw_instanced(instance_count);

Each instance gets a different @builtin(instance_index) in the vertex shader.
Use this to index into an array of transforms/colors/etc."""

[[exercises]]
name = "advanced04"
path = "exercises/advanced/advanced04.rs"
mode = "run"
hint = """
Cubemaps are textures with 6 faces (like a cube surrounding the scene).
Used for:
- Skyboxes (distant environment)
- Environment mapping (reflections)
- Shadow mapping (omnidirectional shadows)

In WGSL:
@binding(0) var env_map: texture_cube<f32>;
let color = textureSample(env_map, sampler, direction_vec);

Sample with a 3D direction vector, not 2D UVs!"""

[[exercises]]
name = "advanced05"
path = "exercises/advanced/advanced05.rs"
mode = "run"
hint = """
Post-processing applies effects to the rendered image as a whole.

Process:
1. Render scene to a texture (not screen)
2. Use that texture as input to a fullscreen quad
3. Fragment shader applies effect (blur, bloom, color grading, etc.)
4. Render final result to screen

Common effects:
- Blur (average surrounding pixels)
- Bloom (bright areas glow)
- Tone mapping (HDR to LDR)
- Color correction"""
